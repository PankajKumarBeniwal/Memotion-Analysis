{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "task-b.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PankajKumarBeniwal/Memotion-Analysis/blob/main/task_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kQek7bB1Vnz"
      },
      "source": [
        "### Loaing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VOb2dqil1Vn9"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, Embedding, GlobalAveragePooling1D \n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyLnVGTg1Vn-"
      },
      "source": [
        "### Reading Image Info from CSV and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JkZd0bo91Vn-"
      },
      "source": [
        "df = pd.read_csv('../input/memotion-dataset-7k/memotion_dataset_7k/labels.csv')\n",
        "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "df = df.drop(columns = ['text_ocr', 'overall_sentiment'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rIK1BS351Vn-"
      },
      "source": [
        "cleaned = df.copy()\n",
        "cleaned.dropna(inplace=True)\n",
        "cleaned.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjtsH_bF1Vn_"
      },
      "source": [
        "# Image Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRDxaCOm1Vn_"
      },
      "source": [
        "### Loading Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eqSIwVAG1Vn_"
      },
      "source": [
        "width = 100\n",
        "height = 100\n",
        "X = []\n",
        "for i in tqdm(range(cleaned.shape[0])):\n",
        "    if i in [119, 4799, 6781, 6784, 6786]:\n",
        "        pass\n",
        "    else:\n",
        "        path = '../input/memotion-dataset-7k/memotion_dataset_7k/images/'+cleaned['image_name'][i]\n",
        "        img = image.load_img(path,target_size=(width,height,3))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255.0\n",
        "        X.append(img)\n",
        "        \n",
        "X = np.array(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QKIfS0Vs1VoA"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwe88OvC1VoA"
      },
      "source": [
        "### Dropping few rows to make shape consistent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kHtIPZ4A1VoA"
      },
      "source": [
        "rows_to_drop = ['image_120.jpg',\n",
        "              'image_4800.jpg',\n",
        "              'image_6782.jpg',\n",
        "              'image_6785.jpg',\n",
        "              'image_6787.jpg',\n",
        "              'image_6988.jpg',\n",
        "              'image_6989.jpg',\n",
        "              'image_6990.png',\n",
        "              'image_6991.jpg',\n",
        "              'image_6992.jpg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2ymSpBPe1VoA"
      },
      "source": [
        "for images in rows_to_drop:\n",
        "    cleaned.drop(cleaned[cleaned['image_name'] == images].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J8ptlZhk1VoB"
      },
      "source": [
        "cleaned = cleaned.replace({'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious':1},\n",
        "                        'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1},\n",
        "                        'offensive': {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1},\n",
        "                        'motivational': {'not_motivational': 0, 'motivational': 1}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s3YMdZrq1VoB"
      },
      "source": [
        "target = cleaned.iloc[:,2:]\n",
        "target.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4X2zd5qq1VoB"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.2, stratify=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsHAl7yX1VoC"
      },
      "source": [
        "### Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KbAx1nB41VoC"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomContrast([.5,2]),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "preprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n",
        "\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0cnmPTKy1VoC"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(X)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0])\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXhBmjYK1VoD"
      },
      "source": [
        "### Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MrRXi8SR1VoD"
      },
      "source": [
        "base_model_1 = tf.keras.applications.ResNet50(input_shape=X[0].shape,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "base_model_2 = tf.keras.applications.VGG16(input_shape=X[0].shape,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XqNA3h981VoD"
      },
      "source": [
        "base_model_1.trainable = False\n",
        "base_model_2.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jAjeHc1VoD"
      },
      "source": [
        "### Model for Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HKZq_iCk1VoE"
      },
      "source": [
        "def image_model():\n",
        "    image_input = tf.keras.Input(shape=(150, 150, 3), name = 'image_input')\n",
        "    image_layers = data_augmentation(image_input)\n",
        "    image_layers = preprocess_input(image_layers)\n",
        "    layer_bm_1 = base_model_1(image_input, training=False)\n",
        "    dropout_layer = Dropout(0.2)(layer_bm_1)\n",
        "    layer_bm_1 = Conv2D(2048, kernel_size=2,padding='valid')(layer_bm_1)\n",
        "    dropout_layer = Dropout(0.2)(layer_bm_1)\n",
        "    layer_bm_1 = Dense(512)(dropout_layer)\n",
        "    dropout_layer = Dropout(0.2)(layer_bm_1)\n",
        "    #layer_bm_2 = base_model_2(image_input, training=False)\n",
        "    #dropout_layer = Dropout(0.2)(layer_bm_2)\n",
        "    #layer_bm_2 = Dense(512)(layer_bm_2)\n",
        "    #dropout_layer = Dropout(0.2)(layer_bm_2)\n",
        "    #layers = tf.keras.layers.concatenate([layer_bm_1, layer_bm_2])\n",
        "    image_layers = GlobalAveragePooling2D()(layer_bm_1)\n",
        "    image_layers = Dropout(0.2, name = 'dropout_layer')(image_layers)\n",
        "    return image_input, image_layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wHGUooOk1VoE"
      },
      "source": [
        "image_input, image_layers = image_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CojOXhPC1VoE"
      },
      "source": [
        "# Text Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwI6eTbg1VoF"
      },
      "source": [
        "### Standardization and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6eq-wrGL1VoF"
      },
      "source": [
        "def standardization(data):\n",
        "    data = data.apply(lambda x: x.lower())\n",
        "    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "    data = data.apply(lambda x: re.sub(r'\\w*.com\\w*', '', x, flags=re.MULTILINE))\n",
        "    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "    return data\n",
        "\n",
        "cleaned['text_corrected'] = standardization(cleaned.text_corrected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbb1RdXd1VoF"
      },
      "source": [
        "### Vectorizing Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SHGsEEOw1VoF"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "vocab_size = 10000\n",
        "sequence_length = 50\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "text_ds = np.asarray(cleaned['text_corrected'])\n",
        "vectorize_layer.adapt(tf.convert_to_tensor(text_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vzKX2Htd1VoF"
      },
      "source": [
        "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(cleaned.text_corrected, target, test_size = 0.2, stratify=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RjbCSiZO1VoG"
      },
      "source": [
        "embedding_dim=16\n",
        "\n",
        "def text_model():\n",
        "    text_input = tf.keras.Input(shape=(None,), dtype=tf.string, name='text')\n",
        "    text_layers = vectorize_layer(text_input)\n",
        "    text_layers = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\")(text_layers)\n",
        "    dropout_layer = Dropout(0.2)(text_layers)\n",
        "    \n",
        "    text_layers = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, activation='relu', return_sequences=True))(text_layers)\n",
        "    dropout_layer = Dropout(0.2)(text_layers)\n",
        "    text_layers = tf.keras.layers.BatchNormalization()(text_layers)\n",
        "\n",
        "    text_layers = tf.keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(text_layers)\n",
        "    dropout_layer = Dropout(0.2)(text_layers)\n",
        "    text_layers = tf.keras.layers.GlobalMaxPooling1D()(text_layers)\n",
        "    dropout_layer = Dropout(0.2)(text_layers)\n",
        "    \n",
        "    text_layers = tf.keras.layers.Dense(2048, activation=\"relu\")(text_layers)\n",
        "    text_layers = tf.keras.layers.Dropout(0.5)(text_layers)\n",
        "    return text_input, text_layers\n",
        "\n",
        "text_input, text_layers = text_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nerLiYPr1VoH"
      },
      "source": [
        "# Combining and Evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvBi4gGH1VoH"
      },
      "source": [
        "### Task A: Overall Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yMmAUowa1VoI"
      },
      "source": [
        "def model(layer_1, layer_2, image_input, text_input):\n",
        "    concatenate = tf.keras.layers.concatenate([layer_1, layer_2], axis=1)\n",
        "    semi_final_layer = tf.keras.layers.Dense(2048, activation='softmax')(concatenate)\n",
        "\n",
        "    prediction_layer = tf.keras.layers.Dense(4, activation='softmax', name = 'task_B_out')\n",
        "    \n",
        "\n",
        "    output = prediction_layer(semi_final_layer)\n",
        "    \n",
        "\n",
        "    model = tf.keras.Model(inputs = [image_input, text_input] , \n",
        "                           outputs = output)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o34lcE2r1VoJ"
      },
      "source": [
        "model = model(image_layers, text_layers, image_input, text_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ik57ouZF1VoK"
      },
      "source": [
        "import os\n",
        "# Define the checkpoint directory to store the checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1Fupp0a71VoL"
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "  if epoch < 5:\n",
        "    return 1.0\n",
        "  elif epoch >= 5 and epoch < 15:\n",
        "    return 0.5\n",
        "  else:\n",
        "    return 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HdMgpLfp1VoL"
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience=5),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "regAycU_1VoL"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics=['categorical_accuracy'])\n",
        "    \n",
        "history = model.fit(x = {\"image_input\": X_train, \"text_input\": X_text_train},\n",
        "                        y= y_train,\n",
        "                        batch_size=32,\n",
        "                        epochs=25,\n",
        "                        validation_data=({\"image_input\": X_test, \"text_input\": X_text_test}, y_test ),\n",
        "                        callbacks=callbacks\n",
        "                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VR-k1giM1VoM"
      },
      "source": [
        "prediction = model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})\n",
        "prediction = np.array(prediction)\n",
        "prediction = np.squeeze(prediction).T\n",
        "prediction = 1/(1+np.exp(-np.array(prediction)))\n",
        "prediction = np.where(prediction > 0.5, 1, 0)\n",
        "y_true = y_test.values\n",
        "\n",
        "\n",
        "micro_f1_score = f1_score(y_true[:4,1], prediction[:4,1], average='micro')\n",
        "macro_f1_score = f1_score(y_true[:4,1], prediction[:4,1], average='macro')\n",
        "\n",
        "print(\"Micro F1 score for Task B is \", micro_f1_score)\n",
        "print(\"Macro F1 score for Task B is \", macro_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CRCDonw-1VoM"
      },
      "source": [
        "pd.DataFrame(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kYLpddg-1VoM"
      },
      "source": [
        "plt.imshow(X[1,:,:,:])\n",
        "target.iloc[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Mw5Tbp1L1VoM"
      },
      "source": [
        "prediction = model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})\n",
        "prediction = np.array(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BtuJk85l1VoN"
      },
      "source": [
        "plt.bar(['humuor', 'sarcasm', 'offensive', 'motivational'], np.where(prediction[:,1,0] > 0.5, 1, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E_aVEEOJ1VoN"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "\n",
        "fig, axes = plt.subplots(1,3, figsize=(12, 4))\n",
        "\n",
        "axes[0].plot(df.loss)\n",
        "axes[0].plot(df.humuor_loss)\n",
        "axes[0].plot(df.sarcasm_loss)\n",
        "axes[0].plot(df.offensive_loss)\n",
        "axes[0].plot(df.motivational_loss)\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Losses')\n",
        "axes[0].set_title('Losses Per Epoch')\n",
        "axes[0].legend(['Humuor loss', 'Sarcasm loss','Offensive loss','Motivational Loss'], loc='upper right')\n",
        "\n",
        "\n",
        "axes[1].plot(df.humuor_accuracy)\n",
        "axes[1].plot(df.sarcasm_accuracy)\n",
        "axes[1].plot(df.offensive_accuracy)\n",
        "axes[1].plot(df.motivational_accuracy)\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('Accuracy Per Epoch')\n",
        "axes[1].legend(['Humuor Acc', 'Sarcasm Acc','Offensive Acc','Motivational Acc'], loc='lower right')\n",
        "\n",
        "\n",
        "\n",
        "axes[2].plot(df.loss)\n",
        "axes[2].set_xlabel('Epochs')\n",
        "axes[2].set_ylabel('Losses')\n",
        "axes[2].set_title('Losses Per Epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ClHFeqZb1VoN"
      },
      "source": [
        "test_images = X_test.shape[0]\n",
        "\n",
        "random_index = np.random.choice(test_images, 5)\n",
        "random_test_images = X_test[random_index, ...]\n",
        "random_test_labels = (y_test.humour[random_index, ...],\n",
        "                      y_test.sarcasm[random_index, ...],\n",
        "                      y_test.offensive[random_index, ...],\n",
        "                      y_test.motivational[random_index, ...])\n",
        "\n",
        "predictions = model.predict(random_test_images)\n",
        "\n",
        "fig, axes = plt.subplots(5, 2, figsize=(16, 12))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
        "\n",
        "for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
        "    axes[i, 0].imshow(np.squeeze(image))\n",
        "    axes[i, 0].get_xaxis().set_visible(False)\n",
        "    axes[i, 0].get_yaxis().set_visible(False)\n",
        "    axes[i, 0].text(10., -1.5, f'Digit {label}')\n",
        "    axes[i, 1].bar(np.arange(1,11), prediction)\n",
        "    axes[i, 1].set_xticks(np.arange(1,11))\n",
        "    axes[i, 1].set_title(\"Categorical distribution. Model prediction\")\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SJkHH2gr1VoN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
